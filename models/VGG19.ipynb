{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq_FNvM2P83m"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD9-kjvc9wcL",
        "outputId": "a7f0830f-13f4-4f74-b474-87b8fbc0b727"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2481it [00:17, 142.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_Train.shape (2481, 150, 150, 3)\n",
            "X_test.shape (745, 150, 150, 3)\n",
            "y_train.shape (1736, 2)\n",
            "y_test.shape (745, 2)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"VGG16_Architecture\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 512)               2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20159298 (76.90 MB)\n",
            "Trainable params: 133378 (521.01 KB)\n",
            "Non-trainable params: 20025920 (76.39 MB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-7f553d7a6767>:133: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.8231 - accuracy: 0.6406 \n",
            "Epoch 1: val_loss improved from inf to 0.65799, saving model to VGG16_Model.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 911s 34s/step - loss: 0.8231 - accuracy: 0.6406 - val_loss: 0.6580 - val_accuracy: 0.5154 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.7329 - accuracy: 0.6746 \n",
            "Epoch 2: val_loss did not improve from 0.65799\n",
            "27/27 [==============================] - 793s 30s/step - loss: 0.7329 - accuracy: 0.6746 - val_loss: 0.6894 - val_accuracy: 0.5114 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.7028 \n",
            "Epoch 3: val_loss did not improve from 0.65799\n",
            "27/27 [==============================] - 792s 30s/step - loss: 0.6557 - accuracy: 0.7028 - val_loss: 0.6611 - val_accuracy: 0.5208 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7267 \n",
            "Epoch 4: val_loss improved from 0.65799 to 0.65323, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 772s 29s/step - loss: 0.6129 - accuracy: 0.7267 - val_loss: 0.6532 - val_accuracy: 0.5221 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.7153 \n",
            "Epoch 5: val_loss improved from 0.65323 to 0.65217, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 772s 29s/step - loss: 0.6210 - accuracy: 0.7153 - val_loss: 0.6522 - val_accuracy: 0.5262 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.7105 \n",
            "Epoch 6: val_loss did not improve from 0.65217\n",
            "27/27 [==============================] - 773s 29s/step - loss: 0.6305 - accuracy: 0.7105 - val_loss: 0.6522 - val_accuracy: 0.5289 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.7099 \n",
            "Epoch 7: val_loss improved from 0.65217 to 0.64128, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5850 - accuracy: 0.7099 - val_loss: 0.6413 - val_accuracy: 0.5436 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7225 \n",
            "Epoch 8: val_loss improved from 0.64128 to 0.61699, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 773s 29s/step - loss: 0.5710 - accuracy: 0.7225 - val_loss: 0.6170 - val_accuracy: 0.5839 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.7339 \n",
            "Epoch 9: val_loss improved from 0.61699 to 0.59716, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5522 - accuracy: 0.7339 - val_loss: 0.5972 - val_accuracy: 0.6242 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.7392 \n",
            "Epoch 10: val_loss improved from 0.59716 to 0.59271, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5638 - accuracy: 0.7392 - val_loss: 0.5927 - val_accuracy: 0.6456 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.7267 \n",
            "Epoch 11: val_loss improved from 0.59271 to 0.57765, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 780s 29s/step - loss: 0.5628 - accuracy: 0.7267 - val_loss: 0.5777 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.7404 \n",
            "Epoch 12: val_loss improved from 0.57765 to 0.57152, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 739s 28s/step - loss: 0.5435 - accuracy: 0.7404 - val_loss: 0.5715 - val_accuracy: 0.6752 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.7273 \n",
            "Epoch 13: val_loss improved from 0.57152 to 0.56288, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 776s 29s/step - loss: 0.5372 - accuracy: 0.7273 - val_loss: 0.5629 - val_accuracy: 0.7020 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7416 \n",
            "Epoch 14: val_loss improved from 0.56288 to 0.54377, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5417 - accuracy: 0.7416 - val_loss: 0.5438 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.7362 \n",
            "Epoch 15: val_loss did not improve from 0.54377\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5349 - accuracy: 0.7362 - val_loss: 0.5469 - val_accuracy: 0.7114 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.7362 \n",
            "Epoch 16: val_loss improved from 0.54377 to 0.53171, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5164 - accuracy: 0.7362 - val_loss: 0.5317 - val_accuracy: 0.7154 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7524 \n",
            "Epoch 17: val_loss improved from 0.53171 to 0.53141, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 775s 29s/step - loss: 0.5196 - accuracy: 0.7524 - val_loss: 0.5314 - val_accuracy: 0.7195 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.7410 \n",
            "Epoch 18: val_loss improved from 0.53141 to 0.51974, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 776s 29s/step - loss: 0.5251 - accuracy: 0.7410 - val_loss: 0.5197 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.7482 \n",
            "Epoch 19: val_loss improved from 0.51974 to 0.50671, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 773s 29s/step - loss: 0.5147 - accuracy: 0.7482 - val_loss: 0.5067 - val_accuracy: 0.7356 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.7434 \n",
            "Epoch 20: val_loss did not improve from 0.50671\n",
            "27/27 [==============================] - 772s 29s/step - loss: 0.5156 - accuracy: 0.7434 - val_loss: 0.5113 - val_accuracy: 0.7302 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.7512 \n",
            "Epoch 21: val_loss did not improve from 0.50671\n",
            "27/27 [==============================] - 790s 30s/step - loss: 0.5100 - accuracy: 0.7512 - val_loss: 0.5085 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.7566 \n",
            "Epoch 22: val_loss did not improve from 0.50671\n",
            "27/27 [==============================] - 775s 29s/step - loss: 0.5017 - accuracy: 0.7566 - val_loss: 0.5071 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.7458 \n",
            "Epoch 23: val_loss improved from 0.50671 to 0.50134, saving model to VGG16_Model.hdf5\n",
            "27/27 [==============================] - 774s 29s/step - loss: 0.5190 - accuracy: 0.7458 - val_loss: 0.5013 - val_accuracy: 0.7517 - lr: 0.0010\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7512 \n",
            "Epoch 24: val_loss did not improve from 0.50134\n",
            "27/27 [==============================] - 772s 29s/step - loss: 0.5250 - accuracy: 0.7512 - val_loss: 0.5053 - val_accuracy: 0.7383 - lr: 0.0010\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.7500 \n",
            "Epoch 25: val_loss did not improve from 0.50134\n",
            "27/27 [==============================] - 772s 29s/step - loss: 0.4948 - accuracy: 0.7500 - val_loss: 0.5177 - val_accuracy: 0.7315 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.7416 \n",
            "Epoch 26: val_loss did not improve from 0.50134\n",
            "27/27 [==============================] - 775s 29s/step - loss: 0.5121 - accuracy: 0.7416 - val_loss: 0.5074 - val_accuracy: 0.7409 - lr: 0.0010\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.7410 \n",
            "Epoch 27: val_loss did not improve from 0.50134\n",
            "27/27 [==============================] - 773s 29s/step - loss: 0.5168 - accuracy: 0.7410 - val_loss: 0.5090 - val_accuracy: 0.7315 - lr: 0.0010\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.7608 \n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.50134\n",
            "27/27 [==============================] - 772s 29s/step - loss: 0.4906 - accuracy: 0.7608 - val_loss: 0.5101 - val_accuracy: 0.7302 - lr: 0.0010\n",
            "Epoch 29/30\n",
            " 7/27 [======>.......................] - ETA: 6:32 - loss: 0.4887 - accuracy: 0.7567"
          ]
        }
      ],
      "source": [
        "#Import Necessary Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import  Flatten, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.applications import VGG19\n",
        "#from keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
        "#import keras_preprocessing\n",
        "!pip install Keras-Preprocessing\n",
        "from keras_preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "\n",
        "#Split Into Train Data & Test Data\n",
        "\n",
        "disease_types=['COVID', 'non-COVID']\n",
        "data_dir = '/home'\n",
        "train_dir = os.path.join(data_dir)\n",
        "\n",
        "train_data = []\n",
        "for defects_id, sp in enumerate(disease_types):\n",
        "    for file in os.listdir(os.path.join(train_dir, sp)):\n",
        "        train_data.append(['{}/{}'.format(sp, file), defects_id, sp])\n",
        "train = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\n",
        "\n",
        "IMAGE_SIZE = 150\n",
        "def read_image(filepath):\n",
        "    return cv2.imread(os.path.join(data_dir, filepath))\n",
        "def resize_image(image, image_size):\n",
        "    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "for i, file in tqdm(enumerate(train['File'].values)):\n",
        "    image = read_image(file)\n",
        "    if image is not None:\n",
        "        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "X_Train = X_train / 255.\n",
        "print('X_Train.shape',X_Train.shape)\n",
        "\n",
        "\n",
        "Y_train = train['DiseaseID'].values\n",
        "Y_train = to_categorical(Y_train, num_classes=2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_Train, Y_train, test_size = 0.3)\n",
        "\n",
        "print('X_test.shape',X_test.shape)\n",
        "print('y_train.shape',y_train.shape)\n",
        "print('y_test.shape',y_test.shape)\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.3)\n",
        "\n",
        "vgg19_model = VGG19(weights = 'imagenet', include_top = False,input_shape=(150,150,3))\n",
        "x = vgg19_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "predictions = Dense(2, activation = 'softmax')(x)\n",
        "model = Model(vgg19_model.input,predictions)\n",
        "for layer in vgg19_model.layers:\n",
        "    layer.trainable = False\n",
        "optimizer = Adam(lr=0.0002)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model._name = \"VGG16_Architecture\"\n",
        "model.summary()\n",
        "\n",
        "#Train the Model\n",
        "\n",
        "annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.70, patience=5, verbose=1, min_lr=1e-4)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "SIZE=64\n",
        "N_ch=3\n",
        "\n",
        "training_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                        width_shift_range=0.2,\n",
        "                        height_shift_range=0.2,\n",
        "                        zoom_range=0.2,\n",
        "                        horizontal_flip=True,\n",
        "                        vertical_flip=True,\n",
        "                        shear_range=0.2)\n",
        "\n",
        "train_generator = training_datagen.flow(\n",
        "\tX_train, Y_train,\n",
        "batch_size=64\n",
        ")\n",
        "training_datagen.fit(X_train)\n",
        "\n",
        "filepath=\"VGG16_Model.hdf5\"\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True, mode='min',verbose=1)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=360,\n",
        "                        width_shift_range=0.2,\n",
        "                        height_shift_range=0.2,\n",
        "                        zoom_range=0.2,\n",
        "                        horizontal_flip=True,\n",
        "                        vertical_flip=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
        "               steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "               epochs=EPOCHS,\n",
        "               verbose=1,\n",
        "               callbacks=[annealer, checkpoint],\n",
        "               validation_data=(X_val, Y_val))\n",
        "\n",
        "#Plot the Results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('TraiN & Val Acc VS Epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('TraiN & Val Loss VS Epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "model.load_weights(\"VGG16_Model.hdf5\")\n",
        "score = model.evaluate(X_val, Y_val ,verbose=1)\n",
        "print('Test Loss:', score[0])\n",
        "\n",
        "\n",
        "Y_pred = model.predict(X_val)\n",
        "Y_predx = np.argmax(Y_pred, axis = -1)\n",
        "Y_valx = np.argmax(Y_val, axis = -1)\n",
        "cf_matrix = confusion_matrix(Y_valx, Y_predx)\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot = labels, fmt = '')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "\n",
        "cfmatrix = confusion_matrix(Y_valx, Y_predx)\n",
        "precision = precision_score(Y_valx, Y_predx)\n",
        "recall = recall_score(Y_valx, Y_predx)\n",
        "f1score = f1_score(Y_valx, Y_predx)\n",
        "\n",
        "print('Test accuracy:', score[1]*100)\n",
        "print(f\"Confusion Score = {cfmatrix}\")\n",
        "print(f\"Precision = {precision}\")\n",
        "print(f\"Recall = {recall}\")\n",
        "print(f\"F1 Score = {f1score}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}